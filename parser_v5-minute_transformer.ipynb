{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import events\n",
    "import os\n",
    "import dataset\n",
    "import numpy as np\n",
    "import timestamps\n",
    "\n",
    "MINUTES = 60 * 4\n",
    "SRC_DIR = 'dataset/bob_all_processed_mins'\n",
    "MINUTES_DIR = f'dataset/transformed_minutes/interval_{str(MINUTES)}m'\n",
    "TIMESTAMP_DIR = f'dataset/transformed_timestamps/interval_{str(MINUTES)}m'\n",
    "POPULATED_DIR = f'dataset/transformed_populated/interval_{str(MINUTES)}m'\n",
    "FILLED_DIR = f'dataset/transformed_filled/interval_{str(MINUTES)}m'\n",
    "TIMESTAMPS = timestamps.get_all_timestamps()\n",
    "\n",
    "os.makedirs(MINUTES_DIR, exist_ok=True)\n",
    "os.makedirs(POPULATED_DIR, exist_ok=True)\n",
    "os.makedirs(FILLED_DIR, exist_ok=True)\n",
    "os.makedirs(TIMESTAMP_DIR, exist_ok=True)\n",
    "\n",
    "files = os.scandir(SRC_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform to N minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2020_79.csv: Feeding Treatment Swarming \n",
      "Processing 2022_97.csv: \n",
      "Processing 2022_152.csv: Honey \n",
      "Processing 2022_82.csv: \n",
      "Processing 2022_96.csv: \n",
      "Processing 2022_69.csv: \n",
      "Processing 2020_87.csv: Honey \n",
      "Processing 2020_93.csv: \n",
      "Processing 2020_123.csv: Feeding \n",
      "Processing 2020_78.csv: \n",
      "Processing 2021_132.csv: \n",
      "Processing 2021_126.csv: Feeding Honey Treatment \n",
      "Processing 2021_118.csv: Swarming \n",
      "Processing 2020_85.csv: Honey \n",
      "Processing 2020_109.csv: Feeding Honey Treatment \n",
      "Processing 2022_57.csv: \n",
      "Processing 2022_151.csv: \n",
      "Processing 2022_95.csv: \n",
      "Processing 2022_56.csv: \n",
      "Processing 2020_90.csv: Feeding Honey Treatment \n",
      "Processing 2020_84.csv: \n",
      "Processing 2020_120.csv: \n",
      "Processing 2020_47.csv: \n",
      "Processing 2021_109.csv: \n",
      "Processing 2021_135.csv: Feeding \n",
      "Processing 2020_43.csv: \n",
      "Processing 2020_57.csv: \n",
      "Processing 2020_118.csv: Feeding Treatment Swarming \n",
      "Processing 2020_80.csv: \n",
      "Processing 2022_141.csv: \n",
      "Processing 2020_95.csv: \n",
      "Processing 2020_119.csv: Feeding Treatment Swarming \n",
      "Processing 2020_56.csv: \n",
      "Processing 2021_134.csv: Feeding Treatment \n",
      "Processing 2021_108.csv: \n",
      "Processing 2021_136.csv: Honey \n",
      "Processing 2020_68.csv: \n",
      "Processing 2020_97.csv: Feeding Treatment \n",
      "Processing 2022_79.csv: \n",
      "Processing 2021_0.csv: \n",
      "Processing 2019_11.csv: Feeding \n",
      "Processing 2020_96.csv: Honey \n",
      "Processing 2020_69.csv: Feeding \n",
      "Processing 2021_123.csv: Feeding Treatment Swarming \n",
      "Processing 2022_5.csv: \n",
      "Processing 2020_26.csv: Feeding Honey Treatment \n",
      "Processing 2019_62.csv: Feeding Honey \n",
      "Processing 2021_72.csv: Feeding Honey Treatment Died \n",
      "Processing 2021_99.csv: \n",
      "Processing 2021_67.csv: \n",
      "Processing 2020_27.csv: Feeding Treatment \n",
      "Processing 2019_49.csv: Feeding Honey \n",
      "Processing 2021_58.csv: Honey \n",
      "Processing 2021_64.csv: \n",
      "Processing 2021_70.csv: \n",
      "Processing 2022_126.csv: \n",
      "Processing 2019_48.csv: \n",
      "Processing 2022_21.csv: \n",
      "Processing 2020_5.csv: \n",
      "Processing 2019_5.csv: Feeding \n",
      "Processing 2019_58.csv: Honey \n",
      "Processing 2021_60.csv: \n",
      "Processing 2022_136.csv: \n",
      "Processing 2022_123.csv: Feeding \n",
      "Processing 2021_49.csv: Honey \n",
      "Processing 2020_21.csv: Feeding Honey \n",
      "Processing 2020_0.csv: \n",
      "Processing 2021_141.csv: Honey Treatment \n",
      "Processing 2019_6.csv: \n",
      "Processing 2022_26.csv: Feeding Honey Treatment \n",
      "Processing 2022_109.csv: \n",
      "Processing 2022_135.csv: Feeding Honey Treatment \n",
      "Processing 2021_88.csv: Feeding Honey Treatment \n",
      "Processing 2021_76.csv: \n",
      "Processing 2022_134.csv: \n",
      "Processing 2021_62.csv: \n",
      "Processing 2022_27.csv: \n",
      "Processing 2020_36.csv: Feeding Treatment Swarming \n",
      "Processing 2020_3.csv: \n",
      "Processing 2019_43.csv: Died \n",
      "Processing 2022_139.csv: \n",
      "Processing 2021_84.csv: \n",
      "Processing 2021_90.csv: \n",
      "Processing 2021_85.csv: \n",
      "Processing 2019_56.csv: Feeding \n",
      "Processing 2022_17.csv: Feeding Honey Swarming \n",
      "Processing 2022_112.csv: Honey \n",
      "Processing 2021_86.csv: Feeding Swarming \n",
      "Processing 2021_79.csv: \n",
      "Processing 2022_107.csv: \n",
      "Processing 2021_69.csv: Feeding Honey Swarming \n",
      "Processing 2021_96.csv: \n",
      "Processing 2021_82.csv: \n",
      "Processing 2021_97.csv: Feeding Swarming \n",
      "Processing 2019_46.csv: \n",
      "Processing 2022_100.csv: \n",
      "Processing 2021_95.csv: \n",
      "Processing 2021_57.csv: Died \n",
      "Processing 2022_101.csv: Swarming \n",
      "Processing 2022_115.csv: \n",
      "Processing 2022_129.csv: \n",
      "Processing 2020_17.csv: Feeding Honey \n",
      "Processing 2020_58.csv: Feeding Honey Treatment \n",
      "Processing 2020_64.csv: \n",
      "Processing 2020_103.csv: \n",
      "Processing 2022_49.csv: Honey \n",
      "Processing 2022_75.csv: \n",
      "Processing 2020_102.csv: \n",
      "Processing 2021_107.csv: Honey \n",
      "Processing 2021_111.csv: Feeding \n",
      "Processing 2020_67.csv: \n",
      "Processing 2020_73.csv: \n",
      "Processing 2020_98.csv: \n",
      "Processing 2020_100.csv: \n",
      "Processing 2020_128.csv: Swarming \n",
      "Processing 2022_62.csv: \n",
      "Processing 2021_27.csv: \n",
      "Processing 2021_26.csv: Feeding Honey Treatment Swarming \n",
      "Processing 2019_22.csv: \n",
      "Processing 2022_88.csv: \n",
      "Processing 2020_115.csv: \n",
      "Processing 2020_101.csv: \n",
      "Processing 2020_72.csv: Feeding Honey \n",
      "Processing 2020_66.csv: Feeding Honey \n",
      "Processing 2021_128.csv: \n",
      "Processing 2021_100.csv: \n",
      "Processing 2020_62.csv: \n",
      "Processing 2020_76.csv: Honey Swarming \n",
      "Processing 2020_105.csv: Treatment Died Swarming \n",
      "Processing 2020_89.csv: \n",
      "Processing 2020_111.csv: Feeding Honey Treatment \n",
      "Processing 2022_67.csv: \n",
      "Processing 2019_26.csv: \n",
      "Processing 2021_36.csv: Swarming \n",
      "Processing 2019_27.csv: Feeding \n",
      "Processing 2020_104.csv: \n",
      "Processing 2020_77.csv: \n",
      "Processing 2021_101.csv: Swarming \n",
      "Processing 2021_115.csv: \n",
      "Processing 2021_129.csv: Feeding Treatment \n",
      "Processing 2020_75.csv: \n",
      "Processing 2020_49.csv: Honey \n",
      "Processing 2020_112.csv: Feeding Honey Died Swarming \n",
      "Processing 2022_70.csv: \n",
      "Processing 2022_58.csv: Honey \n",
      "Processing 2019_25.csv: \n",
      "Processing 2021_21.csv: Feeding \n",
      "Processing 2020_107.csv: Feeding Treatment \n",
      "Processing 2020_48.csv: Feeding Treatment Died Swarming \n",
      "Processing 2020_60.csv: Honey \n",
      "Processing 2020_74.csv: \n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = pd.read_csv(file.path, dtype={\n",
    "        't_i_1': float,\n",
    "        't_i_2': float,\n",
    "        't_i_3': float,\n",
    "        't_i_4': float,\n",
    "        't_o': float,\n",
    "        'weight_kg': float,\n",
    "        \"weight_delta\": float,\n",
    "        'numeric.time': float,\n",
    "        'h': float,\n",
    "        't': float,\n",
    "        'p': float,\n",
    "    }, low_memory=False, parse_dates=['time'], index_col='time', date_format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    df: pd.DataFrame = df.infer_objects(copy=False)\n",
    "\n",
    "    \n",
    "    print(f'Processing {file.name}: ', end='')\n",
    "    \n",
    "    has_queencell = events.populate_event_column(df, 'queencell')\n",
    "    has_feeding = events.populate_event_column(df, 'feeding')\n",
    "    has_honey = events.populate_event_column(df, 'honey')\n",
    "    has_treatment = events.populate_event_column(df, 'treatment')\n",
    "    has_died = events.populate_event_column(df, 'died')\n",
    "    has_swarming = events.populate_event_column(df, 'swarming')\n",
    "    \n",
    "    # if has_queencell:\n",
    "    #     print(f' Queencell')\n",
    "    if has_feeding:\n",
    "        print(f'Feeding', end=' ')\n",
    "    if has_honey:\n",
    "        print(f'Honey', end=' ')\n",
    "    if has_treatment:\n",
    "        print(f'Treatment', end=' ')\n",
    "    if has_died:\n",
    "        print(f'Died', end=' ')\n",
    "    if has_swarming:\n",
    "        print(f'Swarming', end=' ')\n",
    "    print()\n",
    "    \n",
    "    # odf = pd.DataFrame(columns=columns)\n",
    "    odf = df.resample(f'{MINUTES}min').agg({\n",
    "        'X.1': 'first',\n",
    "        'X': 'first',\n",
    "        'key': 'first',\n",
    "\n",
    "        't_i_1': 'mean',\n",
    "        't_i_2': 'mean',\n",
    "        't_i_3': 'mean',\n",
    "        't_i_4': 'mean',\n",
    "        't_i_5': 'mean',\n",
    "        't_o': 'mean',\n",
    "        \n",
    "        'weight_kg': 'mean',\n",
    "        \n",
    "        'h': 'mean',\n",
    "        't': 'mean',\n",
    "        'p': 'mean',\n",
    "        \n",
    "        'year': 'first',\n",
    "        'month': 'first',\n",
    "        'day': 'first',\n",
    "        'hour': 'first',\n",
    "        'minute': 'first',\n",
    "        \n",
    "        'queencell.next.dif': 'first',\n",
    "        'feeding.next.dif': 'first',\n",
    "        'honey.next.dif': 'first',\n",
    "        'treatment.next.dif': 'first',\n",
    "        'died.next.dif': 'first',\n",
    "        'swarming.next.dif': 'first',\n",
    "        \n",
    "        'swarming': 'max',\n",
    "        'queencell': 'max',\n",
    "        'feeding': 'max',\n",
    "        'honey': 'max',\n",
    "        'treatment': 'max',\n",
    "        'died': 'max',\n",
    "    })\n",
    "    \n",
    "    # Convert columns to integer type before saving\n",
    "    odf['month'] = odf['month'].fillna(0).astype(int)\n",
    "    odf['day'] = odf['day'].fillna(0).astype(int)\n",
    "    odf['year'] = odf['year'].fillna(0).astype(int)\n",
    "    odf['hour'] = odf['hour'].fillna(0).astype(int)\n",
    "    odf['minute'] = odf['minute'].fillna(0).astype(int)\n",
    "    odf['swarming'] = odf['swarming'].fillna(0).astype(int)\n",
    "    odf['feeding'] = odf['feeding'].fillna(0).astype(int)\n",
    "    odf['honey'] = odf['honey'].fillna(0).astype(int)\n",
    "    odf['treatment'] = odf['treatment'].fillna(0).astype(int)\n",
    "    odf['died'] = odf['died'].fillna(0).astype(int)\n",
    "    odf['queencell'] = odf['queencell'].fillna(0).astype(int)\n",
    "    \n",
    "    odf = odf.round(2)\n",
    "    odf.drop(columns=['X.1', 'X', 'key', 'queencell.next.dif','feeding.next.dif','honey.next.dif','treatment.next.dif','died.next.dif','swarming.next.dif'], inplace=True)\n",
    "    # odf['time'] = odf.index\n",
    "    odf.to_csv(f'{MINUTES_DIR}/{file.name}', index=True, index_label='time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2019_5.csv\n",
      "Processing 2019_5.csv\n",
      "Processing 2020_48.csv\n",
      "Processing 2020_48.csv\n",
      "Processing 2020_105.csv\n",
      "Processing 2019_49.csv\n",
      "Processing 2019_56.csv\n",
      "Processing 2019_58.csv\n",
      "Processing 2020_0.csv\n",
      "Processing 2020_26.csv\n",
      "Processing 2020_27.csv\n",
      "Processing 2020_36.csv\n",
      "Processing 2020_47.csv\n",
      "Processing 2020_48.csv\n",
      "Processing 2020_66.csv\n",
      "Processing 2020_69.csv\n",
      "Processing 2020_72.csv\n",
      "Processing 2020_72.csv\n",
      "Processing 2020_76.csv\n",
      "Processing 2020_84.csv\n",
      "Processing 2020_89.csv\n",
      "Processing 2020_90.csv\n",
      "Processing 2020_95.csv\n",
      "Processing 2020_96.csv\n",
      "Processing 2020_96.csv\n",
      "Processing 2020_97.csv\n",
      "Processing 2020_97.csv\n",
      "Processing 2020_100.csv\n",
      "Processing 2021_0.csv\n",
      "Processing 2020_105.csv\n",
      "Processing 2020_105.csv\n",
      "Processing 2020_107.csv\n",
      "Processing 2020_111.csv\n",
      "Processing 2020_111.csv\n",
      "Processing 2020_111.csv\n",
      "Processing 2020_112.csv\n",
      "Processing 2020_118.csv\n",
      "Processing 2020_119.csv\n",
      "Processing 2021_21.csv\n",
      "Processing 2020_123.csv\n",
      "Processing 2020_123.csv\n",
      "Processing 2021_27.csv\n",
      "Processing 2020_128.csv\n",
      "Processing 2021_67.csv\n",
      "Processing 2021_76.csv\n",
      "Processing 2021_79.csv\n",
      "Processing 2021_86.csv\n",
      "Processing 2021_97.csv\n",
      "Processing 2021_100.csv\n",
      "Processing 2021_109.csv\n",
      "Processing 2021_118.csv\n",
      "Processing 2022_21.csv\n",
      "Processing 2021_123.csv\n",
      "Processing 2021_123.csv\n",
      "Processing 2021_126.csv\n",
      "Processing 2022_26.csv\n",
      "Processing 2022_26.csv\n",
      "Processing 2021_141.csv\n",
      "Processing 2022_88.csv\n",
      "Processing 2022_123.csv\n",
      "Processing 2022_129.csv\n",
      "Processing 2022_134.csv\n",
      "Processing 2022_135.csv\n",
      "Processing 2022_151.csv\n"
     ]
    }
   ],
   "source": [
    "for stamp in TIMESTAMPS:\n",
    "    name = f\"{stamp['year']}_{stamp['hive_number']}.csv\"\n",
    "    print(f\"Processing {name}\")\n",
    "    df = dataset.read_dataset_file(os.path.join(MINUTES_DIR, name))\n",
    "    if 'ignore' in stamp:\n",
    "        df[[stamp['ignore']]] = None\n",
    "    date_from: pd.Timestamp = pd.to_datetime(stamp['date_from'])\n",
    "    date_to:pd.Timestamp = pd.to_datetime(stamp['date_to'])\n",
    "    \n",
    "    # if stamp['year'] == '2022' and stamp['hive_number'] == '88':\n",
    "    #     mask = df.index < pd.Timestamp('2022-02-22 18:00')\n",
    "    #     df.index = df.index + pd.Timedelta(days=9, hours=1).where(mask, pd.Timedelta(0))\n",
    "    #     date_from = df.index.min()\n",
    "        \n",
    "    df = df.loc[date_from:date_to]\n",
    "    out_name = f\"{stamp['year']}_{stamp['hive_number']}__{date_from.month}-{date_from.day}={date_to.month}-{date_to.day}.csv\"\n",
    "    df.to_csv(os.path.join(TIMESTAMP_DIR, out_name), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.scandir(TIMESTAMP_DIR)\n",
    "for file in files:\n",
    "    df = dataset.read_dataset_file(file.path)\n",
    "    if '2020_118__5-28=6-9' in file.name:\n",
    "        df = dataset.fill_with_historical_pattern(df, ['t_i_1', 't_i_2', 't_i_3', 't_i_4', 't_i_5', 't_o', 't', 'weight_kg'], hours_ago=48)\n",
    "    if '2020_112__6-8=6-22' in file.name:\n",
    "        df = dataset.fill_with_historical_pattern(df, ['t_o'], hours_ago=48)\n",
    "    if '2022_88__1-' in file.name:\n",
    "        # Shift records before 2022-02-22 18:00 forward by 9 days and 1 hour\n",
    "        cutoff_date = pd.to_datetime('2022-02-22 18:00')\n",
    "        time_shift = pd.Timedelta(days=9, hours=1)\n",
    "        # Create mask for records before cutoff\n",
    "        mask = df.index < cutoff_date\n",
    "        # Apply time shift to matching records\n",
    "        df.index = pd.to_datetime(np.where(mask, \n",
    "                                        df.index + time_shift,\n",
    "                                        df.index))\n",
    "        # Sort index after shifting\n",
    "        df.sort_index(inplace=True)\n",
    "    df.infer_objects(copy=False)\n",
    "    df.bfill()\n",
    "    df.to_csv(os.path.join(FILLED_DIR, file.name), index=True, index_label='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2020_119__5-28=5-30.csv: Smoothing Populating \n",
      "Processing 2021_126__8-14=8-28.csv: Smoothing Populating \n",
      "Processing 2021_79__2-22=6-15.csv: Smoothing Populating \n",
      "Processing 2020_26__8-28=9-17.csv: Smoothing Populating \n",
      "Processing 2021_86__5-21=6-4.csv: Smoothing Populating \n",
      "Processing 2020_107__7-21=8-1.csv: Smoothing Populating \n",
      "Processing 2021_123__3-1=4-15.csv: Smoothing Populating \n",
      "Processing 2020_72__7-9=7-14.csv: Smoothing Populating \n",
      "Processing 2021_67__4-2=4-21.csv: Smoothing Populating \n",
      "Processing 2019_58__11-8=11-10.csv: Smoothing Populating \n",
      "Processing 2020_48__1-1=1-14.csv: Smoothing Populating \n",
      "Processing 2019_43__11-26=12-8.csv: Smoothing Populating \n",
      "Processing 2022_21__2-15=3-26.csv: Smoothing Populating \n",
      "Processing 2020_69__7-16=7-23.csv: Smoothing Populating \n",
      "Processing 2020_105__5-28=5-31.csv: Smoothing Populating \n",
      "Processing 2022_129__3-1=4-15.csv: Smoothing Populating \n",
      "Processing 2020_96__9-15=10-1.csv: Smoothing Populating \n",
      "Processing 2020_48__2-1=2-10.csv: Smoothing Populating \n",
      "Processing 2020_97__6-15=7-1.csv: Smoothing Populating \n",
      "Processing 2020_48__3-1=3-15.csv: Smoothing Populating \n",
      "Processing 2020_123__8-17=9-1.csv: Smoothing Populating \n",
      "Processing 2020_72__7-27=8-3.csv: Smoothing Populating \n",
      "Processing 2021_27__9-22=11-20.csv: Smoothing Populating \n",
      "Processing 2020_105__9-1=9-14.csv: Smoothing Populating \n",
      "Processing 2021_123__9-2=9-16.csv: Smoothing Populating \n",
      "Processing 2019_5__9-22=9-26.csv: Smoothing Populating \n",
      "Processing 2021_0__3-17=3-29.csv: Smoothing Populating \n",
      "Processing 2021_100__4-2=5-1.csv: Smoothing Populating \n",
      "Processing 2020_48__2-1=2-14.csv: Smoothing Populating \n",
      "Processing 2019_5__8-28=9-4.csv: Smoothing Populating \n",
      "Processing 2020_47__4-28=5-11.csv: Smoothing Populating \n",
      "Processing 2019_48__12-28=1-14.csv: Smoothing Populating \n",
      "Processing 2020_0__3-4=3-27.csv: Smoothing Populating \n",
      "Processing 2020_66__8-4=8-7.csv: Smoothing Populating \n",
      "Processing 2022_123__12-20=12-30.csv: Smoothing Populating \n",
      "Processing 2022_88__1-5=5-1.csv: Smoothing Populating \n",
      "Processing 2020_76__6-19=6-24.csv: Smoothing Populating \n",
      "Processing 2022_26__2-17=5-1.csv: Smoothing Populating \n",
      "Processing 2019_48__2-1=2-14.csv: Smoothing Populating \n",
      "Processing 2022_134__2-15=4-21.csv: Smoothing Populating \n",
      "Processing 2019_56__8-28=8-31.csv: Smoothing Populating \n",
      "Processing 2020_111__5-2=5-6.csv: Smoothing Populating \n",
      "Processing 2020_105__9-1=10-1.csv: Smoothing Populating \n",
      "Processing 2022_26__9-15=9-22.csv: Smoothing Populating \n",
      "Processing 2021_97__6-15=6-20.csv: Smoothing Populating \n",
      "Processing 2021_118__6-4=6-8.csv: Smoothing Populating \n",
      "Processing 2021_111__3-5=3-14.csv: Smoothing Populating \n",
      "Processing 2021_21__2-25=3-7.csv: Smoothing Populating \n",
      "Processing 2020_100__10-7=11-15.csv: Smoothing Populating \n",
      "Processing 2020_96__12-7=12-20.csv: Smoothing Populating \n",
      "Processing 2020_95__7-15=8-4.csv: Smoothing Populating \n",
      "Processing 2020_36__6-1=6-5.csv: Smoothing Populating \n",
      "Processing 2020_111__7-5=7-20.csv: Smoothing Populating \n",
      "Processing 2020_128__5-8=5-21.csv: Smoothing Populating \n",
      "Processing 2021_76__4-6=5-20.csv: Smoothing Populating \n",
      "Processing 2022_135__7-20=8-25.csv: Smoothing Populating \n",
      "Processing 2020_84__6-22=6-29.csv: Smoothing Populating \n",
      "Processing 2020_123__12-4=12-30.csv: Smoothing Populating \n",
      "Processing 2021_141__8-15=9-15.csv: Smoothing Populating \n",
      "Processing 2020_97__10-7=10-12.csv: Smoothing Populating \n",
      "Processing 2020_90__9-12=9-14.csv: Smoothing Populating \n",
      "Processing 2020_89__5-9=5-15.csv: Smoothing Populating \n",
      "Processing 2019_49__9-6=10-1.csv: Smoothing Populating \n",
      "Processing 2019_43__11-21=11-25.csv: Smoothing Populating \n",
      "Processing 2022_21__2-15=3-15.csv: Smoothing Populating \n",
      "Processing 2020_112__6-8=6-22.csv: Smoothing Populating \n",
      "Processing 2022_151__11-8=12-5.csv: Smoothing Populating \n",
      "Processing 2021_109__3-1=3-14.csv: Smoothing Populating \n",
      "Processing 2020_118__5-28=6-9.csv: Smoothing Populating \n",
      "Processing 2020_111__8-7=8-21.csv: Smoothing Populating \n",
      "Processing 2020_27__10-1=10-13.csv: Smoothing Populating \n"
     ]
    }
   ],
   "source": [
    "files = os.scandir(FILLED_DIR)\n",
    "for file in files:\n",
    "    print(f\"Processing {file.name}:\", end=' ')\n",
    "    \n",
    "    df = dataset.read_dataset_file(file.path)\n",
    "    df.infer_objects(copy=False)                \n",
    "    df.bfill()\n",
    "    print(f\"Smoothing\", end=' ')\n",
    "    df['weight_kg_smoothed'] = dataset.smooth_col(df['weight_kg'])\n",
    "    \n",
    "    df['temp_mid'] = df[['t_i_1', 't_i_2', 't_i_3', 't_i_4', 't_i_5', \"t\"]].median(axis=1, skipna=True)\n",
    "    df['temp_mid_smoothed'] = dataset.smooth_col(df['temp_mid'])\n",
    "    df['temp_diff'] = df['temp_mid'] - df['t_o']\n",
    "    df['temp_ratio'] = df['temp_mid'] / df['t_o']\n",
    "    \n",
    "    df['h'] = dataset.smooth_col(df['h'])\n",
    "    df['p'] = dataset.smooth_col(df['p'])\n",
    "    print(f\"Populating\", end=' ')\n",
    "    df['weight_kg_1_pct'] = df['weight_kg_smoothed'].pct_change(periods=1)\n",
    "    df['weight_kg_2_pct'] = df['weight_kg_smoothed'].pct_change(periods=2)\n",
    "    df['weight_kg_3_pct'] = df['weight_kg_smoothed'].pct_change(periods=3)\n",
    "    df['weight_kg_5_pct'] = df['weight_kg_smoothed'].pct_change(periods=5)\n",
    "    df['weight_kg_8_pct'] = df['weight_kg_smoothed'].pct_change(periods=8)\n",
    "    \n",
    "    df['temp_mid_3_pct'] = df['temp_mid_smoothed'].pct_change(periods=3)\n",
    "    df['temp_mid_5_pct'] = df['temp_mid_smoothed'].pct_change(periods=5)\n",
    "    df['temp_mid_10_pct'] = df['temp_mid_smoothed'].pct_change(periods=10)\n",
    "    \n",
    "    df.to_csv(f'{POPULATED_DIR}/{file.name}', index=True, index_label='time')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
