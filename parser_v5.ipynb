{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import dataset\n",
    "import main\n",
    "import events\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "MINUTES = 20\n",
    "SRC_DIR = 'dataset/bob_all_processed_mins'\n",
    "OUT_DIR = 'dataset/modern/full_dataset_'+str(MINUTES)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "files = os.scandir(SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'time',\n",
    "    't_i_1',\n",
    "    't_i_2',\n",
    "    't_i_3',\n",
    "    't_i_4',\n",
    "    't_i_5',\n",
    "    't_o',\n",
    "    'weight_kg',\n",
    "    'h',\n",
    "    't',\n",
    "    'p',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'hour',\n",
    "    'minute',\n",
    "    'queencell.next.dif',\n",
    "    'feeding.next.dif',\n",
    "    'honey.next.dif',\n",
    "    'treatment.next.dif',\n",
    "    'died.next.dif',\n",
    "    'swarming.next.dif',\n",
    "]\n",
    "\n",
    "files = os.scandir(SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_event(record: pd.Series, e: str):\n",
    "    event = f'{e}.next.dif'\n",
    "    return not (record[event] == 'NA' or record[event] == '' or record[event] == None or math.isnan(record[event]))\n",
    "\n",
    "def to_out_filename(name: str, queencell: bool, feeding: bool, honey: bool, treatment: bool, died: bool, swarming: bool):\n",
    "    queencell = 'q' if queencell else ''\n",
    "    feeding = 'f' if feeding else ''\n",
    "    honey = 'h' if honey else ''\n",
    "    treatment = 't' if treatment else ''\n",
    "    died = 'd' if died else ''\n",
    "    swarming = 's' if swarming else ''\n",
    "    return f'{name.split(\".\")[0]}-{queencell}{feeding}{honey}{treatment}{died}{swarming}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/gbqqwv9j035d81xb9dz_s6kw0000gn/T/ipykernel_69020/1676162586.py:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.bfill()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2020_79.csv\n",
      "Processing 2020_79.csv:\n",
      " Queencell: False\n",
      " Feeding: True\n",
      " Honey: False\n",
      " Treatment: True\n",
      " Died: False\n",
      " Swarming: True\n",
      "MI: 272920/272937\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/gbqqwv9j035d81xb9dz_s6kw0000gn/T/ipykernel_69020/1676162586.py:77: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  odf.bfill()\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:263: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  c.interpolate(method='linear', inplace=True)\n",
      "/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:18: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  perc_deltaDI = (curr[column] - prevDI[column]) / prevDI[column]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['weight_delta_diff'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpopulate_humidity_delta(odf)\n\u001b[1;32m    116\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpopulate_normalized(odf, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_delta_percent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpopulate_normalized(odf, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_delta_diff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpopulate_scaled_weight(odf)\n\u001b[1;32m    120\u001b[0m out_filename \u001b[38;5;241m=\u001b[39m to_out_filename(file\u001b[38;5;241m.\u001b[39mname, has_queencell, has_feeding, has_honey, has_treatment, has_died, has_swarming)\n",
      "File \u001b[0;32m/Volumes/ROG ESD-S1C/PhD/HiveMonitor/dataset.py:113\u001b[0m, in \u001b[0;36mpopulate_normalized\u001b[0;34m(df, column)\u001b[0m\n\u001b[1;32m    111\u001b[0m df[column\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m    112\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m))\n\u001b[0;32m--> 113\u001b[0m scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df[[column]])\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# scaled = scaled[np.isfinite(scaled).all(scaled.mean())]\u001b[39;00m\n\u001b[1;32m    115\u001b[0m df[column\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m scaled\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['weight_delta_diff'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = pd.read_csv(file.path, dtype={\n",
    "        't_i_1': float,\n",
    "        't_i_2': float,\n",
    "        't_i_3': float,\n",
    "        't_i_4': float,\n",
    "        't_o': float,\n",
    "        'weight_kg': float,\n",
    "        \"weight_delta\": float,\n",
    "        'numeric.time': float,\n",
    "        'h': float,\n",
    "        't': float,\n",
    "        'p': float,\n",
    "    }, low_memory=False)\n",
    "\n",
    "    df = df.bfill()\n",
    "    first = df.iloc[0]\n",
    "    print(f\"Processing {file.name}\")\n",
    "    \n",
    "    has_queencell = has_event(first, 'queencell') \n",
    "    has_feeding = has_event(first, 'feeding')\n",
    "    has_honey = has_event(first, 'honey')\n",
    "    has_treatment = has_event(first, 'treatment')\n",
    "    has_died = has_event(first, 'died')\n",
    "    has_swarming = has_event(first, 'swarming')\n",
    "    \n",
    "    print(f'Processing {file.name}:')\n",
    "    print(f' Queencell: {has_queencell}')\n",
    "    print(f' Feeding: {has_feeding}')\n",
    "    print(f' Honey: {has_honey}')\n",
    "    print(f' Treatment: {has_treatment}')\n",
    "    print(f' Died: {has_died}')\n",
    "    print(f' Swarming: {has_swarming}')\n",
    "    \n",
    "    odf = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for i, current in df.iterrows():\n",
    "        if i % MINUTES == 0:\n",
    "            print(f\"MI: {i}/{len(df)}\", end='\\r')\n",
    "            if i > 0:\n",
    "                slice = df.iloc[i-MINUTES:i]\n",
    "                odf.loc[i // MINUTES] = {\n",
    "                    'X.1': current['X.1'],\n",
    "                    'month': current['month'],\n",
    "                    'hour': current['hour'],\n",
    "\n",
    "                    't_i_1': slice['t_i_1'].mean(),\n",
    "                    't_i_2': slice['t_i_2'].mean(),\n",
    "                    't_i_3': slice['t_i_3'].mean(),\n",
    "                    't_i_4': slice['t_i_4'].mean(),\n",
    "                    't_i_5': slice['t_i_5'].mean(),\n",
    "\n",
    "\n",
    "                    't_o': slice['t_o'].mean(),\n",
    "                    'weight_kg': slice['weight_kg'].mean(),\n",
    "\n",
    "                    'h': slice['h'].mean(),\n",
    "                    't': slice['t'].mean(),\n",
    "                    'p': slice['p'].mean(),\n",
    "                    \n",
    "                    'year': current['year'],\n",
    "                    'month': current['month'],\n",
    "                    'day': current['day'],\n",
    "                    'hour': current['hour'],\n",
    "                    'minute': current['minute'],\n",
    "                    \n",
    "                    'queencell.next.dif': current['queencell.next.dif'],\n",
    "                    'feeding.next.dif': current['feeding.next.dif'],\n",
    "                    'honey.next.dif': current['honey.next.dif'],\n",
    "                    'treatment.next.dif': current['treatment.next.dif'],\n",
    "                    'died.next.dif': current['died.next.dif'],\n",
    "                    'swarming.next.dif': current['swarming.next.dif'],\n",
    "                }\n",
    "            else:\n",
    "                odf.loc[i // MINUTES] = current[columns]   \n",
    "                \n",
    "    odf.bfill()\n",
    "    odf['weight_kg'] = dataset.smooth_col(odf['weight_kg'])\n",
    "    odf['t_i_1'] = dataset.smooth_col(odf['t_i_1'])\n",
    "    odf['t_i_2'] = dataset.smooth_col(odf['t_i_2'])\n",
    "    odf['t_i_3'] = dataset.smooth_col(odf['t_i_3'])\n",
    "    odf['t_i_4'] = dataset.smooth_col(odf['t_i_4'])\n",
    "    odf['t_i_5'] = dataset.smooth_col(odf['t_i_5'])\n",
    "\n",
    "    odf['t'] = dataset.smooth_col(odf['t'])\n",
    "    odf['h'] = dataset.smooth_col(odf['h'])\n",
    "    odf['p'] = dataset.smooth_col(odf['p'])\n",
    "    \n",
    "    if has_queencell:\n",
    "        queencell_indexes = events.get_event_indexes(odf, 'queencell.next.dif')\n",
    "        dataset.populate_column_by_index(odf, 'queencell', queencell_indexes)\n",
    "\n",
    "    if has_feeding:\n",
    "        feeding_indexes = events.get_event_indexes(odf, 'feeding.next.dif')\n",
    "        dataset.populate_column_by_index(odf, 'feeding', feeding_indexes)\n",
    "\n",
    "    if has_honey:\n",
    "        honey_indexes = events.get_event_indexes(odf, 'honey.next.dif')\n",
    "        dataset.populate_column_by_index(odf, 'honey', honey_indexes)\n",
    "    \n",
    "    if has_treatment:\n",
    "        treatment_indexes = events.get_event_indexes(odf, 'treatment.next.dif')\n",
    "        dataset.populate_column_by_index(odf, 'treatment', treatment_indexes)\n",
    "    \n",
    "    if has_died:\n",
    "        died_indexes = events.get_event_indexes(odf, 'died.next.dif')\n",
    "        dataset.populate_column_by_index(odf, 'died', died_indexes)\n",
    "    \n",
    "    if has_swarming:\n",
    "        swarming_indexes = events.get_event_indexes(odf, 'swarming.next.dif')\n",
    "        dataset.populate_column_by_index(odf, 'swarming', swarming_indexes)\n",
    "\n",
    "    dataset.populate_delta(odf)\n",
    "    dataset.populate_temp_delta(odf)\n",
    "    dataset.populate_humidity_delta(odf)\n",
    "    \n",
    "    out_filename = to_out_filename(file.name, has_queencell, has_feeding, has_honey, has_treatment, has_died, has_swarming)\n",
    "    odf.to_csv(f'{OUT_DIR}/{out_filename}', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
